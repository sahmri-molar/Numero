---
title: "Numero Introduction"
author: 
- name: Song Gao
  affiliation:
  - &sahmri South Australian Health And Medical Research Institute, Adelaide, Australia
  email: song.gao@sahmri.com  
- name: Stefan Mutter
  affiliation: 
  - *sahmri 
- name: Aaron E. Casey
  affiliation: 
  - *sahmri 
- name: Ville-Petteri Mäkinen
  affiliation: 
  - *sahmri
  - University of Adelaide, School of Biological Sciences, Adelaide, Australia
  - Computational Medicine, Institute of Health Sciences, Faculty of Medicine, University of Oulu, Finland
  
date: "`r doc_date()`"
package: "`r pkg_ver('Numero')`"
output: BiocStyle::html_document2
bibliography: Numero.bib
csl: apa-old-doi-prefix.csl
abstract: >
  Risk is not evenly spread in a population characterised by large number of continuous variables and there are often also no clear clusters of risk. Thus, we need a transparent way to find vulnerable subgroups in the population that can be evaluated critically. In our framework, a large multi-variable dataset is summarised by organising the data samples on a two-dimensional map where the proximity on the map reflects the similarity accross multiple variables simultaneously. Thus, subgroups can be discovered easily in a visual way on the map. The framework is especially useful but not limited to data-driven discovery of epidemiologically, clinically and/or biologically relevant subgroups. The vignette introduces the main concepts, the terminology used and a real world example dataset of a significant health problem. Numero is then introdcued alongside this practical example analysis.
vignette: >
  %\VignetteIndexEntry{Numero Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

<!--
%% \VignetteEngine{knitr::knitr}
-->
```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```
```{r, echo = FALSE, results='asis'}
BiocStyle::markdown()
BiocStyle::markdown(css.files = c('custom.css'))
```

# Prerequisites and Installation

`r Biocpkg('Numero')`  requires `r CRANpkg('Rcpp')` to compile the C++ code that is embedded in the library. To install `r Rpackage('Rcpp')`, use the command:

```{r, eval=FALSE}
install.packages( "Rcpp" )
```

A general overview of `r Rpackage('Rcpp')` can be accessed via:

```{r, eval=FALSE}
vignette('Rcpp-introduction')
vignette('Rcpp-FAQ')
```

After installing `r Rpackage('Rcpp')`, `r Rpackage('Numero')` can be easily installed either via Bioconductor (recommended)

```{r,eval=FALSE}
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("Numero")
```

or by downloding the compressed file package file from Bioconductor and using the following command:

```{r, eval=FALSE}
install.packages( "<download_dir>/<Numero file>.tar.gz", type="source", repos=NULL )
```

```{r setUpLibrary, eval=TRUE, include=FALSE}
library(Numero)
```

# Introduction

The main purpose of `r Biocpkg('Numero')` is to easily visualise and consequently support the definition of subgroups of samples/individuals in a complex, multi-variable dataset. The framework is especially useful but not limited to data-driven discovery of epidemiologically, clinically and/or biologically relevant subgroups.

## Self-organising map (SOM)

`r Rpackage('Numero')` is a multivariate statistical framework that creates a two dimensional map out of a multi-dimensional input. The framework uses a self-organising map (SOM), a well-established unsupervised learning algorithm [@kohonen_som]. A SOM is a non-parametric method in the sense that it makes only mild assumptions about the dataset and it can detect non-linear patterns. The SOM works well as an exploratory complement to the standard medical, biological or epidemiological statistics toolbox. 

Previous versions of this software (written for MatLab) were successfully used on a range of metabolomics data sets for various diseases [@makinen_1h_2008; @makinen_metabolic_2008; @tukiainen_multi-metabolite_2008; @kumpula_characterization_2010; @bernardi_new_2010; @wurtz_characterization_2011; @makinen_metabolic_2012; @kuusisto_interplay_2012; @makinen_triglyceride-cholesterol_2013].

An introduction to the SOM and in particular circular SOM as used in this software can be found the in supplements (Supporting Information 1 (p.2-5)) from @makinen_metabolic_2012. Other introductions to the SOM (with rectangular maps) are in the supplements from @makinen_1h_2008 and @makinen_metabolic_2008.


## Terminology {#subtypesSubgroups}

This section introduces some key terminology around our SOM framework.

**Sample** -- A multivariable dataset contains information about individuals or samples (usually the rows in the data file). In the following, we will refer to these as samples. The SOM positions samples on a two-dimensional map so that samples that are similar are closer together on the two-dimensional map.

**District** -- The SOM is divdided into a fixed number of neighbourhoods. We call these neighbourhoods districts. A sample will be assigned to exactly one district.

**Layout** -- Our SOMs are circular maps. The layout refers to the number of districts a map has. It is an input parameter in our framework

**Colouring** -- A colouring is a visual representation of the values of one variable in a district. For one SOM with *n* variables, we can construct *n* colourings. Think of colourings as showing different aspects of the same underlying map e.g. one colouring for income per district and another one for unemployment rate.

**Profile** -- A profile is a multivariate representation of a district. The distance of the map reflects the similarity of the profiles.

**Subgroup** -- The aim of a `r Rpackage('Numero')` analysis is to define vulnerable subgroups in a population. A subgroup is a set of at least one but usually more districts. They are defined upon visual insepctions of all colourings of a map.
 
Figure 1A shows a map layout with 40 districts. They are numbered from 1 to 40. Figure 1B shows the same map with an example subgroup boundaries. The subgroup under consideration is made up of the samples that were mapped to districts 2, 3, 12, 13, 14, 22, 23, 24, 39 and 40.

![[Figure 1. ](#fig1) Districts and subgroups](subtypesSubgroups.png)

## Study Design {#studyDesign}

In order to detect statistically robust subgroups, a dataset has to be divided into a training set and an evaluation set. The training set is used to put the (training) samples on map districts so that the similarity of the districts' profiles reflect the their distance on the map. During the evaluation phase, the samples in the evaluation set are matched to their closest training sample. Colourings are computed based on the matched evaluation set. 

Thus, `r Rpackage('Numero')` works as a pipeline:

1. Train the SOM

2. Evaluate the SOM:
  + match the samples from the evaluation set
  + produce map colourings

There are sevral possibilities to divide a dataset into a training and evaluation set. In this vignette, we introduce an example where all samples are used for training, matching and colouring, but we limit the training to some of the measured variables. The common example, that we re-produce here, is to train `r Rpackage('Numero')` with the biomarker data (e.g. serum measurements) and visualise (subgroups for) that data and additional data on disease (e.g. diabetic kidney disease) and data on survival. Therefore, the SOM reveals subgroups that were more vulnerable to disease at baseline and had a highr risk of death at follow-up. These subgroups were based on biomarker data.

However, our framework is not limited to such a setup. Other splits of samples for training and evaluating are possible but not part of this introduction. In general, `r Rpackage('Numero')` allows to use a subset of samples and/or a subset of variables for training and evaluation. Therefore, there are three ways to build the training and evaluation sets:

1. Use all samples and a subset of variables for training and the remaining variables for testing. This vignette is an example fo such an approach. In this case matching is easy as we already know the district for each sample. It can reveal for example how baseline measurements (training) influence risk at follow-up by using the follow-up variables in evaluation only.

2. Use all variables and a subset of samples for training and the remaining samples for evaluation. In this case, the samples in the evaluation set are matched to the closest sample in the training set. This approach can be used to reveal subgroups for the same variables in a different cohort for example.

3. Use a subset of samples and a subset of variables for training and the remaining samples and variables for evaluation. This approach is a combination of the two previous ones.

## Example dataset of diabetic kidney disease

In course of their lifetime, around 1/3 of individuals with type 1 diabetes will develop diabetic kidney disease. Diabetic kindey disease is a decline in kidney function which can be diagnosed by urinary excretion of albumin. Generally, a minimum of two measurements are required to determine the renal disease class. Here, diabetic kidney disease is defined as having macroalbuminuria (an urinary albumin excretion rate of at least 200 μg/min in at least two out of three successive overnight urine samples) . Diabetic kindey disease is a major complication in type 1 diabetes that reduces an individual's life expectancy. Diabetic kidney disease is also a major risk factor for developing cardiovascular disease and cardiovascukar mortality risk is significantly higher in individuals with diabetic kidney. Currently, it is not fully understood why a subset of individuals with type 1 diabetes develops diabetic kidney disease.

The [FinnDiane](http://www.finndiane.fi) (Finnish Diabetic Nephropathy Study) research project, founded in 1997, is a follow-up study of type 1 diabetes. It aims to uncover the risk factors and mechanisms of diabetic complications especially diabetic kidney disease. Our example dataset contains subset of data on all individuals from a FinnDiane publication [@makinen_1h_2008]. It is cross-sectional with one longitudonal endpoint which is death after on average 8.2 years of follow-up.

Our version of the dataset contains `r nrow(nroMatrix(system.file("extdata", "finndiane_dataset.txt", package = "Numero"), keyvars = "INDEX"))` individuals of whom `r length(which(nroMatrix(system.file("extdata", "finndiane_dataset.txt", package = "Numero"), keyvars = "INDEX")[,"DIAB_KIDNEY"] == 1))` individuals had diabetic kidney disease at baseline.

```{r showReadme, eval = TRUE, echo=FALSE, comment=''}
#read in README file
readmeFile <- system.file("extdata", "README.txt", package = "Numero")
myText <- readLines(readmeFile)

#only show the relevant portion of the README file, if it fails show all
myMin <- max(which(myText == 'Baseline data:'),0)
myMax <- min(which(myText == 'Missing values are shown as \'NaN\'.'),length(myText))
myText <- myText[myMin:myMax]

#display results
cat(myText, sep = '\n')
```

For each individual information on `r ncol(nroMatrix(system.file("extdata", "finndiane_dataset.txt", package = "Numero"), keyvars = "INDEX"))` variables were collected. These variables include:

1. five baseline biomarkers that are important with regards to developing renal and cardiovascular complications in type 1 diabetes:
  + urinary albumin excretion rate,
  + serum creatinine,
  + serum triglycerides, 
  + total cholesterol and
  + HDL2 cholesterol
   
2. age at baseline
3. sex
4. diabetes duration at baseline
5. co-morbidities at baseline:
  + diabetic retinopathy,
  + diabetic kidney disease,
  + macrovascular disease,
  + metabolic syndrome. 
  
6. survival of individuals at follow-up (mean follow-up time 8.2 years)

The aim of our data-driven analysis is to find vulnerable subgroups in these individuals with type 1 diabetes that have a higher risk of death at follow-up. One of the advantages of `r Rpackage('Numero')` is that it can handle a large number of risk factors. In our simpler example case here, there are `r ncol(nroMatrix(system.file("extdata", "finndiane_dataset.txt", package = "Numero"), keyvars = "INDEX")) - 1` potential risk factors. We will also show in our example analysis how to adjust for variables from the dataset that might be confounding the risk.

# The `r Rpackage('Numero')` pipeline

## Overview

`r Rpackage('Numero')` operates as a pipeline: loading the data, pre-processing the data, training the model, matching and colouring. The pre-processing step is not an integral part of `r Rpackage('Numero')` as it can be done natively in R. However, we provide an example in the [pre-processing section](#pre). 

Figure 2 and Table 1 show the complete pipeline.

![[Figure 2. ](#fig2) The `r Rpackage('Numero')` pipeline](pipeline.png)

We will explain each function with the use of an example in the [next section](#howto). There is a link in the table that directly jumps to the corresponding explanation. The list in the table is exhaustive. These are all functions in the `r Rpackage('Numero')` package.

Function | Part of pipeline | Short description 
---------|-----------------------|----------------------
*nroMatrix*|[Load the data](#load)|Import a data matrix from a tab-delimited text file
*nroKmeans*|[Setup  and train the SOM](#setup)|Create the initial seed profile of the SOM
*nroKoho*|[Setup  and train the SOM](#setup)|Create the SOM
*nroTrain*|[Setup  and train the SOM](#setup)|Adapt the SOM to a set of multivariable data
*nroMatch*|[Match individuals/samples](#match)|Compares the multivariate samples to a SOM and determines their location
*nroPermute*|[Estimate map statistics](#stats)|Estimate the statistical significance for a regional pattern using permutations
*nroAggregate*|[Colourise maps and save figures](#colour)|Estimate regional aggregates based on assigned map locations
*nroColorize*|[Colourise maps and save figures](#colour)|Assign colors to subtypes
*nroLabel*|[Colourise maps and save figures](#colour)|Optimise the selection of labels for subtypes
*nroCircus*|[Colourise maps and save figures](#colour)|Create a Scalable Vector Graphics (SVG) code for a map
*nroFigure*|[Colourise maps and save figures](#colour)|Save a map to a Scalable Vector Graphics (SVG) file

Table: Table 1. The functions of the `r Rpackage('Numero')` pipeline.

## Data import {#load}
First we need to load the data into a matrix using the *nroMatrix* function. The data has to be stored in a tab-delimited text file. In our example, the *INDEX* column contains the patient identifier. By declaring it in *keyvars*, it will be automically dealt with in the analysis.
```{r setUpExample, eval=TRUE}
exampleFile <- system.file("extdata", "finndiane_dataset.txt", package = "Numero")
db <- nroMatrix(exampleFile, keyvars = "INDEX")
```

Second, we need to define our training set for the SOM. Our study design is to use the biomarkers from our data set and place individuals on the map according to similarity in these five biomarkers. The aim is to find vulnerable subgroups with regards to disease status and risk of death. Therefore, we will be using all individuals and only the biomarkers for training and all variables for evaluation. Consequently, we simply select a subset of our input matrix for training.

```{r preprocess1, eval=TRUE}
# Select training variables.
trvars <- c("uALB_log", "TG_log", "CHOL", "HDL2C", "CREAT_log")
trdata <- db[,trvars]
```


## Pre-processing and adjustment for confounders {#pre}
Pre-processing the data is an important step. However, it is not an integral part of `r Rpackage('Numero')` as pre-processing support is already provided in *R*.

Here, we standardise the data to eliminate differences in measurement units. Otherwise, one biomarker might unduly dominate the results. We recommend standardisation prior to using our package. In addition, we adjust the data according to sex which is also a common pre-processing step (see @makinen_metabolic_2012 for example). Consequently, our subgroups will not be able to assess risk of death in terms of sex differences in biomarker levels. 

When you conceive your own study, it is important to execute the appropriate pre-processing step in order to have valid results.
```{r preprocess2, eval=TRUE}
# Separate men and women.
men <- which(!(db[,"MALE"] == 0))
women <- which(db[,"MALE"] == 0)

# Standardise training data to reduce gender differences
# and to eliminate differences in measurement units.
trdata[men,] <- scale.default(trdata[men,])
trdata[women,] <- scale.default(trdata[women,])
```

## Setup  and train the SOM {#setup}

After pre-processing, it is time to initialise the SOM. In `r Rpackage('Numero')` we use the centroids of k-Means clusters on the training data. That way, the units in the SOM are initialised based on clusters in the data. The function *nroKmeans* provides this information. The user can choose the number of centroids. 

Then *nroKoho* initialises the SOM using the centroids and a user defined radius for the circular map. The radius controls the layout of the SOM. Here, we choose 3 centroids and set the radius to 3. Figure 1A from the [district section](#subtypesSubgroups) shows a SOM of radius 3.

```{r setup1, eval=TRUE}
# Use K-means clustering to determine seed profiles for the SOM. 
km <- nroKmeans(x=trdata, k = 3)
sm <- nroKoho(seeds=km$centroids, radius = 3)
```

Training of the SOM is now straight-forward by inputting the initialised SOM and the training data into the *nroTrain* function.

```{r setup2, eval=TRUE}
# Train the SOM with the standardized data.
sm <- nroTrain(som=sm, x=trdata)
```

## Sample positions on the map {#match}

The next step after training is to match samples to exactly one district. This best matching district is also referred to as best matching unit (BMU) in the code. Since each district of the map is represented with a mutivariable profile, a sample of multivariable data can be compared against each district to find the one that has the most similar profile. This defines the positions of samples on the map.

The matching is found by the *nroMatch* function. The function takes the SOM and the data as input. It outputs a data frame with a row for each sample and three columns: BMU contains the best matching district number and two columns QUALITY and RDATA that can be used to assess the quality of the SOM. We discuss the two quality column in their own section on [SOM qauality](#qm) as they are not an integral part of the pipeline. For now, the column of interest is the best matching district one.

```{r match1, eval=TRUE}
# Find best-matching subtypes for all samples.
matches <- nroMatch(som=sm, x=trdata)
```

As the output below shows, the individual in the first row is matched to district `r head(matches$BMU)[1]`, the individual in the second row to district `r head(matches$BMU)[2]`, etc.

```{r match2, eval=TRUE}
# Show the first best-matching subtypes
head(matches$BMU)
```

Having the matching as a separate step in the pipeline allows splitting the dataset into training and evaluation set in different ways depending on your [study design](#studyDesign).

## Estimate statistics {#stats}

The next step in the pipeline is to estimate the significance of a SOM pattern e.g. whether significant differences between districts on the map exist for a variable. This is important as the SOM algorithm finds a pattern for "true" as well as random data. Therefore, estimating statistics gives an idea on whether differences across the map with regards to a variable can by explained by chance. This is also important for the next step in the pipeline as the colouring of the map should reflect statistical significance. That way the colourings can be compared and interpreted easily.

By definition p-values show the chance that the difference in the random patterns could be more extreme than what we observed from the "true" data. Following this definition, we use permutations and the *nroPermute* function to calculate statistical significance. It takes the SOM, the best matching districts, the values of the variable under consideration and the maximum number of permutations (the default value is 10,000).

Permuations of sample labels to obtain models of the null hypothesis is a well-established concept to estimate p-values. This concept is simple and only relies only on weak distributional assumptions (see @holmes_permut for details).

For each variable, *nroPermute*, performs the following procedure: In each permutation, it randomly assigns best matching districts to all samples/individuals and re-calculates the district values for this random assignment. The function then counts in how many permutations the standard deviations for random data are the same or more extreme than the standard deviation  for the "true" data. The resuting p-value for the variable under consideration is simply this count divided by the number of permutations.

To use the *nroPermute* function in your pipeline, simply loop over all variables.

```{r stats1, eval=TRUE}
# Determine statistics for all variables.
stats <- matrix(NA, ncol(db), 5)
rownames(stats) <- colnames(db)
for( vname in colnames(db) ) {
    
    # Check if a training variable.
    nsim <- NA
    pos <- match(vname, trvars)
    if(is.na(pos)) nsim <- 10000
 
    # Estimate dynamic range of variation.
    tmp <- nroPermute(map=sm, x=db[,vname], bmus=matches$BMU, n=nsim)
    colnames(stats) <- colnames(tmp)
    stats[vname,] <- as.matrix(tmp)
}
```

In this example, the output of *nroPermute* is saved in a data frame called stats. It contains five columns: 

* P is a parametric estimate for statistical significance,

* FREQ is the frequency-based estimate for statistical significance, 

* Z is the estimated z-score of how far the observed map plane is from the average randomly generated layout in units of standard deviation. Thus, a z-score close to zero indicates that there is no *true* signal. 

* NDATA indicates how many data values were used, and 

* NSIM tells the number of completed permutations.

```{r stats2, eval=TRUE}
print(stats)
```

Note that since the training variables are directly responsible for the sample mapping, they all have  non-meaningful p-values, which cannot be used for results interpretation.

## Visualise regional patterns {#colour}

As stated previously, the main purpose of the framework is to easily visualise and consequently support the definition of subgroups of samples. Therefore, `r Rpackage('Numero')` offers visualisation support in its pipeline. 

However, to faciliate intuitive but statistically sound interpretation, care needs to be taken when assigning colours and there are pipeline functions that support this.

For example, let us assume we are preparing the map colourings for triglycerides levels. We have a value for the triglyceride level in each district and different value will have to be assigned to different colours. For example low triglyceride levels can be encoded in blue and they change smoothly to a red color for the highest levels. This is analogous to colouring a map of a metropolitain area based on average house prices in the metropolitain districts. However, in order to compare different colourings for example triglycerides with age or house prices with income, it needs to be visually clear from just looking at these different colourings, which of these are based on random differences between districts and which are based on *true* differences. We already know from the [previous section](#stats) which variables have such statistically significant patterns. To incorporate statistical significance into colourings, the intensity of colours for each colouring will based on statistical significance. 

Z-scores allow to compare different variables as they rank the variables from the *least random* or most informative to the *most random* or least informative. In our case, sex is the least informative variable. The importance of a variable can be conveniently encoded into the intensity of colourings, so that when different map colourings are compared against one another, the one with with brightest colours indicates more pronounced differences between the districts.   

Therefore, we first define a global colour range for all colourings where the intensity mirrors statistical significance and then, we pick a colour from the range to represent a district's average value.

### Define the global colour range

The significance of the differences among districts is encoded into one dynamic colour range for all variable colourings of the SOM as the code below shows. This range is based on z-scores.

```{r colour1}
# Determine suitable dynamic color range across all variables.
# The middle point between the mean training variable score and
# the strongest evaluation variable usually works well.
tr <- which(is.na(stats[,"P"]))
ev <- which(stats[,"P"] >= 0.0)
zbase <- 0.5*(mean(stats[tr,"Z"], na.rm=TRUE)
              + max(stats[ev,"Z"], na.rm=TRUE))

# Make sure the base scale is large enough to prevent non-significant
# signals from getting bright colors.
zbase <- max(zbase, 2.0)

# Set color scale factors. Ideally, these should all be between
# 0 and 1. In practice, it is often better to adjust the scale
# so that the strongest evaluation variable gets a reasonable
# value (e.g. between 0.5 and 1.0), whereas the training variables
# can be over 1.
amplitudes <- stats[,"Z"]/zbase
```


### Define the actual colour for each subtype

After having defined the colour range for the SOM, we colour all districts of the map for each variable indepdendent of whether the variable has been used in training or testing. As you can see in the code below, we simply loop through all the variables: `r colnames(db)`.

Defining the actual colour for a district is a two step process: calculating the actual numeric value for the district and given the colour range determining where in the range this value lies. The first step is performed by *nroAggregate* and the second step by *nroColorize* for each variable

The *nroAggregate* takes the SOM *sm*, the values of the variable from the dataset and the best matching districts *BMU* and outputs a numeric estimate for each district. *nroColorize* chooses the colour given that district value and the colour range.

The function *nroLabel* places a few labels (the district values) on the map so that the map colours can be interpreted and put into context without cluttering of text. Without using *nroLabel*, the users would not know which colour correspond to which value.

In the penultimate step, we create the *svg* file with *nroCircus*. As you can see in the code below, we add a title and the p-value to the map output. This is recommended, as this information is essential when interpreting the map.

Lastly, *nroFigure* saves the *svg* content to a file.

```{r colour3, eval=FALSE}
# Process each variable separately. Note that to make the color scales
# comparable, all the statistics had to be estimated beforehand.
for( vname in colnames(db) ) {

     # Estimate subtype values.
     plane <- nroAggregate(map=sm, x=db[,vname], bmus=matches$BMU)
     
     # Determine subtype colors.
     clrs <- nroColorize(values=plane, amplitude=amplitudes[vname])

     # Determine which subtype labels should be shown.
     labs <- nroLabel(map=sm, values=plane)
     
     # Create a vector graphics object.
     pval <- stats[vname,"P"]
     ttxt <- vname
     if(is.na(pval) == FALSE) { # add p-value for evaluation variables
         ttxt <- sprintf("%s, P = %.2e", vname, pval);
     }
     smfig <- nroCircus(map=sm, colors=clrs, labels=labs, title=ttxt)
     
     # Save figure.
     fpath <- paste(vname, ".svg", sep="")
     nroFigure(file=fpath, scene=smfig)
}

```

One note regarding value estimation in *nroAggregate*: Because of matching, it is possible to train the SOM on standardised and adjusted values but to colour the SOM according to the true original data value. Consequently, the parameter *x* in the *nroAggregate* function is set to the original data vector and not the standardised and adjusted training vector. An example for this is HDL2 cholesterol in Figure 4C in the [results section](#visual). 

This is the end of the analysis pipeline. An example colouring for type 1 diabetes duration can be found in the section on [map colourings](#mapColourings).

# Results and interpretation {#interpretation}

## Map statistics {#mapStats}

Looking at the statistics output again from a results perspective, we can immediatly see that there are subgroups associated with different levels of risk of death at follow-up. Also all other variables used for evaluation except of sex (which has been adjusted for in the pre-processing step) also show significant subgroup patterns. All these patterns are associated witn differences in baseline biomarker levels.
```{r stats3, echo=FALSE,eval=TRUE}
print(stats)
```

Looking at diabetic kidney disease at baseline, it is not suprising to be able to find different subgroups in the SOM as we used albumin excretion rate at baseline in the training which is used to define diabetic kidney disease. The interesting question that the colourings can reveal in the next [section](#mapColourings) is how the diabetic kidney disease subgroups related to the risk of death at follow-up.

## Map colourings {#mapColourings}

To illustrate, how to interpret a map colouring, have a look at Figure 3 which shows the resulting colouring for type 1 diabetes duration.

![[Figure 3. ](#fig3) Colouring for type 1 diabetes duration](T1D_DURAT.svg)

Above the map, there is the name of the variable and its p-value. Here, districts with a shorter diabetes duration are all in the bottom left area of the map. These could be a potential subgroup.

### Define subgroups {#visual}

The interesting part in the analysis is to compare different colourings and define subgroups. Thanks to the colourings for each variable we can do this visually and this is a major advantage of the framework. 

However, keep in mind the SOM itself does not categorise the samples into subgroups, it compresses the mutivariable input into a two-dimensional canvas so that we can better understand it. It is then up to us to decide on subgroupings and whether these subgroups seem plausible and important based on previous knowledge and the map [statistics](#mapStats) and [quality](#qm). This approach to subgrouping is transparent and can be critically evaluated. This is different to defining clusters or subgroups prior to the analysis or base them on strict mathematical criteria. A population-based human cohort like our example one represents a continuous spectrum of various stages and degrees of severity and combinations of symptopms and biomarkers. Thus, there is no *true* cluster structure in the strict mathematical sense. Consequently, the choice of mathematical boundary criteria will be determining the size and often the numbers of clusters which might not be useful for a specific application. In our example death at follow-up is the result of a complex interaction of biomarkers and disease that is not completely understood yet. As we do not fully understand the risk, it is hard to define explicit criteria for that risk. However, the colourings allow us to find individuals at risk and look at the multivariate profiles and therefore, implicitly uncover risk criteria. 

Figure 4 shows our example subgroup analysis. This is one possible subgrouping out of many ones and we need to evaluate it based on our previous knowledge or published scientific findings.

![[Figure 4. ](#fig4) Subgroups in our type 1 diabetes examples](subgroupingExample.png)

Our subgrouping here is based on two colourings: the one for type 1 diabetes duration and the one for the metabolic syndrome (MS) at baseline (Figure 4A).Both colourings represent a statistically significant pattern as p-values on top of their maps indicate. MS is a cluster of conditions: increased blood pressure, high blood sugar, excess body fat around the waist, and abnormal cholesterol or triglyceride levels. In our training data we had cholesterol and triglycerides level and as we can see these two biomarkers alone can reliably find subgroups for MS in our cohort. 

One possible subgrouping of districts is to divide the SOM into three subgroups. As we chose diabetes duration and metabolic syndrome, our subgroups will reveal how these two variables influence risk of death at follow-up and other diseases and diabetic complications like diabetic kidney disease at baseline. As Figure 4A shows, the three subgroups are: 

1. One with a higher diabetes duration and higher prevalence of MS at baseline (Subgroup *Higher Duration*) on the top right side,

2. one with a longer diabetes duration and low prevalence of MS (Subgroup *Low MS*) at the bottom right and

3. one with a shorter diabetes duration but differences in the prevalence of MS (Subgroup *Shorter Duration*) on the left side of the map.

Now that the subgroups are defined and we know which districts belong to a subgroup, you can go back into the SOM output and calculate averages for each variable and subgroup.

We are now interested how our three subgroups do in terms of baseline disease and death at follow up (Figure 4B). 

For baseline disease, we can see that Subgroup *Higher Duration* was likely to also have diabetic kidney disease at baseline. We can also see that a long diabetes duration has not necessarily led to kidney disease as Subgroup *Low MS* had a longer duration of type 1 diabetes but also lower percentages of kidney disease. The interesting finding here is that a longer diabetes duration and a lower prevalence of MS at baseline goes side by side with lower prevalence of diabetes kidney disease. Subgroup *Shorter Duration* has a low prevalence of diabetic kidney disease independent of the prevalence of MS. Thus, the duration of diabetes is an important indicator when looking at the prevalence of baseline diabetic kidney disease. Individuals that had diabetes for longer had more time to develop kidney disease before the baseline assessment. However, our subgroup analysis also shows that MS is associated with a higher prevalence of diabetic kidney disease in individuals with a longer diabetes duration.

Looking at risk of death at follow-up, it is Subgroup *Higher duration* that has a higher prevalence of MS and longer diabetes duration that is most vulnerable to die during the follow-up period. These indidividuals also have a high prevalence of diabetic kidney disease.

We can also compare our subgroups to other biomarkers. Figure 4C shows an example for the urinary albumin extraction rate. We can see that Subgroup *Higher Duration* had a higher extrection rate. We can also see that the region in the map with high albumin aligns perfectly with the one for diabetic kidney disease. This is not surprising as diabetic kidney disease is diagnosed here by albumin extrection rate. This alignment is of such a good quality as albumin extrection rate was used during training and defines diabetic kidney disease that was only used during evaluation. As albumin was used in training, the map does not show a p-value. Colourings of variables used in training tend to be overly optimistic (overfitted) and thus biased if they have been estimated with the same set up samples like we did here. It is important to keep that in mind when interpreting the result.

Figure 4D shows another nice property of having visual maps. As explained, the data was adjusted for sex prior to the analysis. A successful adjustment means that there are no patterns on the map colouring for sex. Looking at the SOM colouring for male, we cannot see any pattern and the p-value for the SOM is not significant at the 0.05 level either.

## Result summary {#conclusions}

The risk of death is spread unevenly among our study population of individuals with type 1 diabetes. Our analysis shows that a subgroup that is characterised by a longer diabetes duration and high prevalence of MS baseline is most at risk of death at follow-up indepdent of the sex of the individuals. This risk is only conveyed in a subgroup where individuals had both a longer diabetes duration and were more likely to have MS. This subgroup is also characterised by a high prevalence of diabetic kindey disease at baseline. Diabetes kidney disease shows a highly signifant pattern as its defining biomarker albumin excretion rate was used during training. In summary, the combination of a longer diabetes duration and the higher prevalence of MS are together associated with an increased risk all-cause mortality. One reason for the high mortality rate in this subgroup of patients is potentially the high prevalence of diabetic kidney disease.

# Map quality {#qm}
Statistical significance is not the only factor to check when looking at the colourings and subgroup results. There might be regions in the map that need to be considered more carefully. Consequently, `r Rpackage('Numero')` also visualises whether there were

1. districts that had fewer samples matched to them compared to others ([sample hisogram](#qm1)), or 

2. districts that had a bigger training error compared to the overall map's training error ([matching quality](#qm2)), or

3. districts that were more than other districts affected by missing values ([coverage](#qm3)).

These are important properties to check before reaching conclusions.

The output of the *nroMatch* function forms the basis for the map quality analysis. Figure 5 shows the pipeline to obtain the quality colourings.

![[Figure 5. ](#fig5) Pipeline for quality colourings](pipeline2.png)

As a pre-requisite, you need the output from *nroMatch*. But then it simply follows the main pipeline using the functions *nroAggregate*, *nroColorize*, *nroLabel*, *nroCircus* and finally *nroFigure* to store the results. There is no need to define a colour range. Except for the map title and the file name, *nroColorize*, *nroLabel*, *nroCircus* and *nroFigure* are used in exactly the same way for all three measures. The only difference is the use of the *nroAggregate* function (Figure 5).

## Sample distribution over the SOM {#qm1}

You can use the `r Rpackage('Numero')` pipeline to visiualise the distribution of individuals/samples over the map. Ideally, individuals/samples should be spread evenly over the map, otherwise some districts of the map will have less power to support your conclusions. For this purpose, do not provide a numeric vector to *nroAggregate* (the *x* parameter), just provide the SOM and the best matching districts. 

```{r quality1, eval=FALSE}
# Visualise sample histogram on the map to verify even distribution.
plane <- nroAggregate(map=sm, bmus=matches$BMU)

# Palette parameter is optional
clrs <- nroColorize(values=plane, palette="fire")
labs <- nroLabel(map=sm, values=plane)
smfig <- nroCircus(map=sm, colors=clrs, labels=labs,
                   title="Data histogram")
nroFigure(file="histogram.svg", scene=smfig)
```

Figure 6 shows that in our example a district aggregated information from between 12 to 18 individuals. This is a relatively even spread.

![[Figure 6. ](#fig6) Histogram of sample/individual distribution on the example SOM](histogram.svg)

## Matching quality {#qm2}

To assess the quality of the matching, `r Rpackage('Numero')` compares the overall mean training error to the error for each district. Ideally, the training error should be spread evenly over the map to avoid having one subgroup with a very high training error compared to others.

Technically, the matching quality is computed in the following way: If the overall mean training error is the same as the district's training error the quality measure is 1. If the district's training error is smaller than the mean training error, than the quality measure is smaller than 1, otherwise it is greater than 1. This data is calculated in *nroMatch* and saved in the output column called QUALITY

Consequently, this QUAILTY column can be used as numeric input for *nroAggregate* (*x* parameter) together with the SOM and the best matching districts.

```{r quality2, eval=FALSE}
# Visualise matching quality.
plane <- nroAggregate(map=sm, bmus=matches$BMU, x=matches$QUALITY)

#the palette parameter is optional
clrs <- nroColorize(values=plane, palette="fire")
labs <- nroLabel(map=sm, values=plane)
smfig <- nroCircus(map=sm, colors=clrs, labels=labs,
                   title="Match quality")
nroFigure(file="quality.svg", scene=smfig)
```

Figure 7 shows the quality of our example SOM.

![[Figure 7. ](#fig7) Quality measure for the SOM districts](quality.svg)

Because we used the training samples also for matching, the districts do not show a great divergence from the mean training error.

## Subtype coverage {#qm3}
The coverage map indicates for each district how much data has been available. As different samples are differently affected by missing values, so are the districts. Ideally, 100% (represented by 1.0) of the data has been available but missing values in the dataset might have reduced that number. This visiulation shows whether there are districts that are suffering more than others from missing data.

You will need to feed the RDATA output of the *nroMatch* function together with the SOM and the best matching districts into *nroAggregate*.

```{r quality3, eval=FALSE}
# Visualise the amount of data available per subtype.
plane <- nroAggregate(map=sm, bmus=matches$BMU, x=matches$RDATA)

#the palette parameter is optional
clrs <- nroColorize(values=plane, palette="fire")
labs <- nroLabel(map=sm, values=plane)
smfig <- nroCircus(map=sm, colors=clrs, labels=labs,
                   title="Data coverage")
nroFigure(file="coverage.svg", scene=smfig)
```

As Figure 8 shows that despite some missing values in our dataset, we still achieve good coverage in each district (>= 98%) .

![[Figure 8. ](#fig8) Coverage map for the SOM districts](coverage.svg)

## Map quality conclusions for our example analysis

As we just presented in this section, the map quality for this example analysis is sufficient to support our [conclusions](#conclusions).

# References



